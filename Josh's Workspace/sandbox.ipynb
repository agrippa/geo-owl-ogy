{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import segpy\n",
    "from segpy.reader import create_reader\n",
    "from segpy.writer import write_segy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "from scipy.stats import mode\n",
    "from scipy.special import kl_div\n",
    "from scipy.stats import entropy\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "%run bp_smc_example.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir('small_dataset'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split up stack and gather files into separate directories\n",
    "for filename in os.listdir('small_dataset'):\n",
    "    src = 'small_dataset/' + filename\n",
    "    if 'gather' in filename:\n",
    "        dst = 'gather/' + filename\n",
    "        shutil.copy(src, dst)\n",
    "    if 'stack' in filename:\n",
    "        dst = 'stack/' + filename\n",
    "        shutil.copy(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename:              stack/img_12.stack.segy\n",
      "SEG Y revision:        SegYRevision.REVISION_0\n",
      "Number of traces:      1058\n",
      "Data format:           IBM 32 bit float\n",
      "Dimensionality:        0\n",
      "\n",
      "=== BEGIN TEXTUAL REEL HEADER ===\n",
      "C01  BP syntheitc Date: 05/20/2019                                              \n",
      "C02  image stack scenario with the following dimension                          \n",
      "C03  axis  :         z         x         y                                      \n",
      "C04  size  :       400      1058         1                                      \n",
      "C05  origin:   0.00000   0.00000   0.00000                                      \n",
      "C06  delta :  10.00000  10.00000  10.00000                                      \n",
      "=== END TEXTUAL REEL HEADER ===\n"
     ]
    }
   ],
   "source": [
    "print_segy_info('stack/img_12.stack.segy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary of arrays for every realization in stack\n",
    "stack_dict = {}\n",
    "for filename in os.listdir('stack')[1:-1]:\n",
    "    arr = np.zeros((1058, 400))\n",
    "\n",
    "    with open(f'stack/{filename}', 'rb') as segy_in_file:\n",
    "        segy_reader = create_reader(segy_in_file, endian='>')\n",
    "\n",
    "        for trace_index in segy_reader.trace_indexes():\n",
    "            data = segy_reader.trace_samples(trace_index)\n",
    "            for i in range(len(data)):\n",
    "                arr[trace_index, i] = data[i]\n",
    "        stack_dict[filename] = arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary of arrays for every realization in stack\n",
    "gather_dict = {}\n",
    "for filename in os.listdir('gather')[1:-1]:\n",
    "    arr = np.zeros((1058, 39, 400))\n",
    "    with open(f'gather/{filename}', 'rb') as segy_in_file:\n",
    "        segy_reader = create_reader(segy_in_file, endian='>')\n",
    "\n",
    "        count = 0\n",
    "        for trace_index in segy_reader.trace_indexes():\n",
    "            data = segy_reader.trace_samples(trace_index)\n",
    "            for i in range(len(data)):\n",
    "                arr[int(trace_index / 39), trace_index % 39, i] = data[i]\n",
    "        gather_dict[filename] = arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the two dictionaries into the directory to use later\n",
    "# joblib.dump(stack_dict, 'stack_dict')\n",
    "stack_dict = joblib.load(open('stack_dict', 'rb'))\n",
    "\n",
    "# joblib.dump(gather_dict, 'gather_dict')\n",
    "gather_dict = joblib.load(open('gather_dict', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "1058\n"
     ]
    }
   ],
   "source": [
    "thing = stack_dict['img_12.stack.segy']\n",
    "print(len(thing[0]))\n",
    "\n",
    "print(len(thing))\n",
    "\n",
    "# there 1058 instances of 400 elements arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn dictionary into pixel arrays (1058 x 400)\n",
    "stack_arr = {}\n",
    "\n",
    "for key in stack_dict.keys():\n",
    "    arr = stack_dict[key]\n",
    "    arr = arr.transpose()\n",
    "    min_arr = arr.min()\n",
    "    max_arr = arr.max()\n",
    "    arr = (arr - min_arr) / (max_arr - min_arr)\n",
    "    arr = arr * 255\n",
    "    stack_arr[key] = arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode_func(x):\n",
    "    values, counts = np.unique(x, return_counts=True)\n",
    "    m = counts.argmax()\n",
    "    return values[m], \n",
    "\n",
    "def kl_divergence(p, q):\n",
    "    return np.sum(np.where(p != 0, p * np.log(p / q), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function computes the uncertainty image of all the stack segy files\n",
    "cnt = Counter()\n",
    "\n",
    "def uncertainty_image(pixel_arr):\n",
    "    kl_scores = []\n",
    "    kl_arr = np.zeros((58, 1058, 400))\n",
    "    i = 0\n",
    "    for key in pixel_arr.keys():\n",
    "        j = 0\n",
    "        for arr in pixel_arr[key]:\n",
    "            bins = np.linspace(arr.min(), arr.max(), num=10)\n",
    "            binned_arr = np.digitize(arr, bins)\n",
    "            \n",
    "            cnt = Counter()\n",
    "            for val in binned_arr:\n",
    "                cnt[val] += 1\n",
    "            cnt = sorted(cnt.items())\n",
    "            \n",
    "            freq_arr = [x[1] for x in cnt]\n",
    "            max_val = max(freq_arr)\n",
    "            mode_bin = freq_arr.index(max(freq_arr)) + 1\n",
    "            onehot_arr = [1e-9 if x != max_val else 1 for x in freq_arr]\n",
    "            freq_arr = np.array(freq_arr) / 400\n",
    "            \n",
    "\n",
    "            kl_score = kl_divergence(freq_arr, onehot_arr)\n",
    "            kl_scores.append(kl_score)\n",
    "            score_arr = np.full((1, 400), kl_score)\n",
    "            kl_arr[i, j, :] = score_arr\n",
    "            j += 1\n",
    "        score_arr = kl_arr[i, :, :]\n",
    "        min_arr = arr.min()\n",
    "        max_arr = arr.max()\n",
    "        score_arr = (score_arr - min_arr) / (max_arr - min_arr)\n",
    "        score_arr = score_arr * 255\n",
    "        im = Image.fromarray(score_arr)\n",
    "        im = im.convert('RGB')\n",
    "        images.append(im)\n",
    "        i += 1\n",
    "        \n",
    "#     for i in range(58):\n",
    "#         images.append(kl_arr[i])\n",
    "    return kl_scores, images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_scores, images = uncertainty_image(stack_arr)\n",
    "dictionary = sorted(Counter(kl_scores).items())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
